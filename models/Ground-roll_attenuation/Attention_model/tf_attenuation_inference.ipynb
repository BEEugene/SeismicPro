{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground-roll attenuation model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import segyio\n",
    "from tqdm import tqdm\n",
    "import sh\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from seismicpro.batchflow import Dataset, DatasetIndex, Pipeline, V\n",
    "\n",
    "from seismicpro.src import (SeismicBatch, FieldIndex, TraceIndex,\n",
    "                            seismic_plot, spectrum_plot, merge_segy_files)\n",
    "from seismicpro.models import FieldMetrics\n",
    "from seismicpro.src.file_utils import write_segy_file\n",
    "from seismicpro.src.seismic_batch import FILE_DEPENDEND_COLUMNS\n",
    "\n",
    "from unet import u_net, conv_block\n",
    "\n",
    "%env CUDA_VISIBLE_DEVICES=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index raw dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>HighCutSlope</th>\n",
       "      <th>TraceWeightingFactor</th>\n",
       "      <th>CDP_X</th>\n",
       "      <th>SourceSurfaceElevation</th>\n",
       "      <th>TraceIdentifier</th>\n",
       "      <th>ShotPoint</th>\n",
       "      <th>SubWeatheringVelocity</th>\n",
       "      <th>SourceY</th>\n",
       "      <th>SourceType</th>\n",
       "      <th>DayOfYear</th>\n",
       "      <th>...</th>\n",
       "      <th>SourceGroupScalar</th>\n",
       "      <th>SourceMeasurementExponent</th>\n",
       "      <th>GeophoneGroupNumberLastTraceOrigField</th>\n",
       "      <th>CDP</th>\n",
       "      <th>TRACE_SAMPLE_COUNT</th>\n",
       "      <th>GainType</th>\n",
       "      <th>NStackedTraces</th>\n",
       "      <th>ElevationScalar</th>\n",
       "      <th>TRACE_SEQUENCE_FILE</th>\n",
       "      <th>file_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502930</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>37281</td>\n",
       "      <td>0</td>\n",
       "      <td>6700517</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1745712</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/notebooks/egor/noise_dataset_1/DN01_shots_for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502880</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>37281</td>\n",
       "      <td>0</td>\n",
       "      <td>6700517</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1745710</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>/notebooks/egor/noise_dataset_1/DN01_shots_for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502905</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>37281</td>\n",
       "      <td>0</td>\n",
       "      <td>6700517</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1745711</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>/notebooks/egor/noise_dataset_1/DN01_shots_for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502830</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>37281</td>\n",
       "      <td>0</td>\n",
       "      <td>6700517</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1745708</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/notebooks/egor/noise_dataset_1/DN01_shots_for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502855</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>37281</td>\n",
       "      <td>0</td>\n",
       "      <td>6700517</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1745709</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>/notebooks/egor/noise_dataset_1/DN01_shots_for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  HighCutSlope TraceWeightingFactor   CDP_X SourceSurfaceElevation  \\\n",
       "                                                                     \n",
       "0            0                    0  502930                     37   \n",
       "1            0                    0  502880                     37   \n",
       "2            0                    0  502905                     37   \n",
       "3            0                    0  502830                     37   \n",
       "4            0                    0  502855                     37   \n",
       "\n",
       "  TraceIdentifier ShotPoint SubWeatheringVelocity  SourceY SourceType  \\\n",
       "                                                                        \n",
       "0               0     37281                     0  6700517          0   \n",
       "1               0     37281                     0  6700517          0   \n",
       "2               0     37281                     0  6700517          0   \n",
       "3               0     37281                     0  6700517          0   \n",
       "4               0     37281                     0  6700517          0   \n",
       "\n",
       "  DayOfYear  ... SourceGroupScalar SourceMeasurementExponent  \\\n",
       "             ...                                               \n",
       "0        43  ...                 1                         0   \n",
       "1        43  ...                 1                         0   \n",
       "2        43  ...                 1                         0   \n",
       "3        43  ...                 1                         0   \n",
       "4        43  ...                 1                         0   \n",
       "\n",
       "  GeophoneGroupNumberLastTraceOrigField      CDP TRACE_SAMPLE_COUNT GainType  \\\n",
       "                                                                               \n",
       "0                                     0  1745712               3000        0   \n",
       "1                                     0  1745710               3000        0   \n",
       "2                                     0  1745711               3000        0   \n",
       "3                                     0  1745708               3000        0   \n",
       "4                                     0  1745709               3000        0   \n",
       "\n",
       "  NStackedTraces ElevationScalar TRACE_SEQUENCE_FILE  \\\n",
       "                                                 raw   \n",
       "0              0               1                   1   \n",
       "1              0               1                   2   \n",
       "2              0               1                   3   \n",
       "3              0               1                   4   \n",
       "4              0               1                   5   \n",
       "\n",
       "                                             file_id  \n",
       "                                                 raw  \n",
       "0  /notebooks/egor/noise_dataset_1/DN01_shots_for...  \n",
       "1  /notebooks/egor/noise_dataset_1/DN01_shots_for...  \n",
       "2  /notebooks/egor/noise_dataset_1/DN01_shots_for...  \n",
       "3  /notebooks/egor/noise_dataset_1/DN01_shots_for...  \n",
       "4  /notebooks/egor/noise_dataset_1/DN01_shots_for...  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_raw = '/notebooks/egor/noise_dataset_1/DN01_shots_for_lift_well.sgy'\n",
    "\n",
    "index = TraceIndex(name='raw', extra_headers='all', path=path_raw)\n",
    "index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/notebooks/egor/gazprom-neft/SeismicPro/models/Ground-roll_attenuation/Attention_model/tf_model2.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input (?, 3000, 1)\n",
      "conv_block_0 (?, 3000, 8)\n",
      "pool_0 (?, 1500, 8)\n",
      "conv_block_1 (?, 1500, 16)\n",
      "pool_1 (?, 750, 16)\n",
      "conv_block_2 (?, 750, 32)\n",
      "pool_2 (?, 375, 32)\n",
      "bottom_conv_block_3 (?, 375, 64)\n",
      "up_2 (?, 750, 64)\n",
      "concat_3 (?, 750, 96)\n",
      "up_conv_block_3 (?, 750, 32)\n",
      "up_1 (?, 1500, 32)\n",
      "concat_2 (?, 1500, 48)\n",
      "up_conv_block_2 (?, 1500, 16)\n",
      "up_0 (?, 3000, 16)\n",
      "concat_1 (?, 3000, 24)\n",
      "up_conv_block_1 (?, 3000, 8)\n",
      "attention (?, 3000, 1)\n",
      "attention_sum (?, 1, 1)\n",
      "sigm_x (?, 3000, 1)\n",
      "attention_sigmoid (?, 3000, 1)\n",
      "input (?, 3000, 1)\n",
      "conv_block_0 (?, 3000, 16)\n",
      "pool_0 (?, 1500, 16)\n",
      "conv_block_1 (?, 1500, 32)\n",
      "pool_1 (?, 750, 32)\n",
      "conv_block_2 (?, 750, 64)\n",
      "pool_2 (?, 375, 64)\n",
      "conv_block_3 (?, 375, 128)\n",
      "pool_3 (?, 188, 128)\n",
      "conv_block_4 (?, 188, 256)\n",
      "pool_4 (?, 94, 256)\n",
      "bottom_conv_block_5 (?, 94, 512)\n",
      "up_4 (?, 188, 512)\n",
      "concat_5 (?, 188, 768)\n",
      "up_conv_block_5 (?, 188, 256)\n",
      "up_3 (?, ?, 256)\n",
      "concat_4 (?, 375, 384)\n",
      "up_conv_block_4 (?, 375, 128)\n",
      "up_2 (?, 750, 128)\n",
      "concat_3 (?, 750, 192)\n",
      "up_conv_block_3 (?, 750, 64)\n",
      "up_1 (?, 1500, 64)\n",
      "concat_2 (?, 1500, 96)\n",
      "up_conv_block_2 (?, 1500, 32)\n",
      "up_0 (?, 3000, 32)\n",
      "concat_1 (?, 3000, 48)\n",
      "up_conv_block_1 (?, 3000, 16)\n",
      "out_main (?, 3000, 1)\n",
      "weights (?, 3000, 1)\n",
      "INFO:tensorflow:Restoring parameters from /notebooks/egor/gazprom-neft/SeismicPro/models/Ground-roll_attenuation/Attention_model/tf_model2.ckpt\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    trace_raw = tf.placeholder('float', shape=(None, 3000, 1), name='trace_in')\n",
    "    targets = tf.placeholder('float', shape=(None, 3000, 1), name='target')\n",
    "    alpha = tf.placeholder('float', name='alpha')\n",
    "    beta = tf.placeholder('float', name='beta')\n",
    "    learning_rate = tf.placeholder('float', name='learning_rate')\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    \n",
    "    #Attention branch\n",
    "    with tf.variable_scope(\"attention_scope\"):\n",
    "        out_attention = u_net(trace_raw, depth=3, filters=8, kernel_size=3,\n",
    "                              activation='elu', is_training=is_training)\n",
    "        out_attention = conv_block(out_attention, 'ca', filters=1, kernel_size=3,\n",
    "                                   activation='sigmoid')\n",
    "        print('attention', out_attention.get_shape())\n",
    "\n",
    "    attention_sum = tf.reduce_sum(out_attention, axis=1, keepdims=True)\n",
    "    print('attention_sum', attention_sum.get_shape())\n",
    "\n",
    "    #Define a domain for sigmoid function\n",
    "    sigm_x = tf.fill(tf.shape(out_attention), 0.0)\n",
    "    arange = tf.range(0, tf.cast(tf.shape(sigm_x)[1], 'float'), dtype='float')\n",
    "    arange = tf.expand_dims(arange, axis=-1)\n",
    "    sigm_x = sigm_x - arange + attention_sum\n",
    "    print('sigm_x', sigm_x.get_shape())\n",
    "    \n",
    "    #Apply sigmoid function to the above obtained domain\n",
    "    attention_sigmoid = tf.sigmoid(sigm_x)\n",
    "    print('attention_sigmoid', attention_sigmoid.get_shape())\n",
    "    \n",
    "    #Main branch\n",
    "    with tf.variable_scope(\"main_scope\"):\n",
    "        out_main = u_net(trace_raw, depth=5, filters=16, kernel_size=7,\n",
    "                         activation='elu', is_training=is_training)\n",
    "        out_main = conv_block(out_main, 'c', filters=1, kernel_size=3)\n",
    "    print('out_main', out_main.get_shape())\n",
    "    \n",
    "    #Get a model output that is a superposition of raw input and main branches\n",
    "    #according to attention mask\n",
    "    predictions = trace_raw * attention_sigmoid + out_main * (1 - attention_sigmoid)\n",
    "\n",
    "    #Loss compontents\n",
    "    noise_loss = tf.losses.absolute_difference(targets, predictions)\n",
    "    cone_loss = alpha * tf.reduce_mean(1 - attention_sigmoid)\n",
    "    sigm_loss = beta * tf.losses.absolute_difference(attention_sigmoid, out_attention)\n",
    "    \n",
    "    #Loss for attention mask and denoising\n",
    "    total_loss = noise_loss + sigm_loss + cone_loss\n",
    "#     total_loss = tf.clip_by_value(total_loss, 0, .1)\n",
    "\n",
    "    #Weights for cone noise loss\n",
    "    weights = (1 - attention_sigmoid) / tf.reduce_sum(1 - attention_sigmoid)\n",
    "    print('weights', weights.get_shape())\n",
    "\n",
    "    #Denoising loss within ground-roll cone\n",
    "    cone_noise_loss = tf.losses.absolute_difference(targets, predictions,\n",
    "                                                    reduction=tf.losses.Reduction.SUM,\n",
    "                                                    weights=weights)\n",
    "#     cone_noise_loss = tf.clip_by_value(cone_noise_loss, 0, .1)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    \n",
    "    main_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                  scope='main_scope')\n",
    "    attention_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                       scope='attention_scope')\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        step_attention = optimizer.minimize(total_loss, var_list=attention_vars)\n",
    "        step_main = optimizer.minimize(total_loss, var_list=main_vars)\n",
    "        step_cone = optimizer.minimize(cone_noise_loss, var_list=main_vars)\n",
    "    \n",
    "    sess = tf.Session(config=config)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to temporary dumps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dump_path = '/data/NA/tmp2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 819/3743 [38:57<2:19:50,  2.87s/it]"
     ]
    }
   ],
   "source": [
    "batch_size = 2000\n",
    "run_set = Dataset(index, SeismicBatch)\n",
    "\n",
    "def dump_single_segy(data, df, samples, path):\n",
    "    \"\"\"Dump data to segy file.\"\"\"\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    headers = list(set(df.columns.levels[0]) - set(FILE_DEPENDEND_COLUMNS))\n",
    "    segy_headers = [h for h in headers if hasattr(segyio.TraceField, h)]\n",
    "    df = df[segy_headers]\n",
    "    df.columns = df.columns.droplevel(1)\n",
    "    write_segy_file(data, df, samples, path)\n",
    "\n",
    "for k in tqdm(range(1 + len(run_set) // batch_size)):\n",
    "    batch = (run_set.next_batch(batch_size, n_epochs=1)\n",
    "             .load(components=('raw',), fmt='segy', tslice=np.arange(3000)))\n",
    "\n",
    "    x = np.expand_dims(np.vstack(batch.raw), -1)\n",
    "\n",
    "    res = sess.run(predictions,\n",
    "                   feed_dict={trace_raw: x, is_training: False})\n",
    "    \n",
    "    df = batch.index.get_df(reset=False)\n",
    "    samples = batch.meta['raw']['samples']\n",
    "    dump_single_segy(res, df, samples, os.path.join(tmp_dump_path, str(k) + '.sgy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to merged file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/notebooks/egor/noise_dataset_1/merged_unetatt_well.sgy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge temporary dumps into single file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_segy_files(output_path=output_path, extra_headers='all',\n",
    "                 path=os.path.join(tmp_dump_path, '*.sgy'))\n",
    "sh.rm(sh.glob(os.path.join(tmp_dump_path, '*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
